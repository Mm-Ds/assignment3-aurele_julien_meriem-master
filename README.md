### Project NÂ° 3 Data Science Lab.
## Adversarial attacks and robust neural networks

Run:

- ```Train_Model.ipynb``` for a demo of the raw model training.
- ```Attacks_demo.ipynb``` for a compelete demo of implemented attacks (FGSM, PGD and C&W).
- ```Adversarial_Training``` for the adversarial training demo.
- ```Other_Tried_Defense_Methods.ipynb``` and ```Test_Other_Tried_Defense_Methods.ipynb``` for other defense methods (Noise injection, input transformations (Crop resize, crop fill, quantization)).
- ```Double_Adversarial.ipynb``` and ```Reverse_Attack.ipyn``` for the "Double Adversarial Attack" demo.
- ```Inspection.ipynb``` for the latent spaces inspection demo.

(model.py, attacks.py, cifar_net.pth, safe_model.pth and unsafe_model.pth need to be uploaded in the running environement) 



